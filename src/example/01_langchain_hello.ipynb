{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ•™å­¦å†…å®¹\n",
    "\n",
    "å¥½çš„ï¼Œæˆ‘æ¥ä¸ºæ‚¨ä»‹ç» Langchain ä¸­è¿™å››ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š\n",
    "\n",
    "### 1. `ChatOpenAI`\n",
    "\n",
    "è¿™æ˜¯ Langchain ä¸­ä¸ OpenAI èŠå¤©æ¨¡å‹ï¼ˆå¦‚ GPT-3.5, GPT-4ï¼‰è¿›è¡Œäº¤äº’çš„æ¥å£ã€‚åœ¨æ‚¨çš„ä»£ç ä¸­ï¼š\n",
    "\n",
    "```python\n",
    "llm = ChatOpenAI(\n",
    "            openai_api_key=api_key,\n",
    "            openai_api_base=base_url,\n",
    "            model_name=model\n",
    ")\n",
    "```\n",
    "\n",
    "*   **ä½œç”¨**ï¼šå®ƒå°è£…äº†è°ƒç”¨ OpenAI API çš„æ‰€æœ‰ç»†èŠ‚ï¼ŒåŒ…æ‹¬èº«ä»½éªŒè¯ï¼ˆ`openai_api_key`ï¼‰ã€API ç«¯ç‚¹ï¼ˆ`openai_api_base`ï¼Œå¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯è‡ªå®šä¹‰æœåŠ¡æˆ–ä»£ç†ï¼‰ä»¥åŠæŒ‡å®šè¦ä½¿ç”¨çš„æ¨¡å‹ï¼ˆ`model_name`ï¼‰ã€‚\n",
    "*   **åŠŸèƒ½**ï¼šåˆ›å»º `ChatOpenAI` å®ä¾‹åï¼Œæ‚¨å°±å¯ä»¥ç”¨å®ƒæ¥å‘é€è¯·æ±‚ç»™å¤§è¯­è¨€æ¨¡å‹å¹¶æ¥æ”¶æ¨¡å‹çš„å›å¤ã€‚\n",
    "\n",
    "### 2. `ChatPromptTemplate`\n",
    "\n",
    "æç¤ºæ¨¡æ¿ï¼ˆPrompt Templateï¼‰æ˜¯ç”¨æ¥æ„å»ºå‘é€ç»™å¤§è¯­è¨€æ¨¡å‹çš„è¾“å…¥ï¼ˆå³æç¤ºï¼‰çš„ã€‚`ChatPromptTemplate` ä¸“é—¨ç”¨äºæ„å»ºèŠå¤©æ¨¡å‹çš„æç¤ºï¼Œé€šå¸¸åŒ…å«ä¸€ç³»åˆ—æ¶ˆæ¯ï¼ˆç³»ç»Ÿæ¶ˆæ¯ã€äººç±»ç”¨æˆ·æ¶ˆæ¯ã€AI åŠ©æ‰‹æ¶ˆæ¯ï¼‰ã€‚\n",
    "\n",
    "åœ¨æ‚¨çš„ä»£ç ä¸­ï¼š\n",
    "\n",
    "```python\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{history}\\nUser: {input}\")\n",
    "])\n",
    "```\n",
    "\n",
    "*   **ä½œç”¨**ï¼šå®ƒå®šä¹‰äº†ä¸æ¨¡å‹äº¤äº’çš„ç»“æ„å’Œä¸Šä¸‹æ–‡ã€‚\n",
    "    *   `(\"system\", \"You are a helpful assistant.\")`ï¼šè¿™æ˜¯ä¸€æ¡ç³»ç»Ÿæ¶ˆæ¯ï¼Œç”¨äºè®¾å®š AI çš„è§’è‰²æˆ–è¡Œä¸ºå‡†åˆ™ã€‚\n",
    "    *   `(\"human\", \"{history}\\nUser: {input}\")`ï¼šè¿™æ˜¯ä¸€æ¡äººç±»ç”¨æˆ·æ¶ˆæ¯çš„æ¨¡æ¿ã€‚å®ƒåŒ…å«äº†ä¸¤ä¸ªå ä½ç¬¦ï¼š`{history}`ï¼ˆç”¨äºä¼ å…¥ä¹‹å‰çš„å¯¹è¯å†å²ï¼‰å’Œ `{input}`ï¼ˆç”¨äºä¼ å…¥ç”¨æˆ·å½“å‰è¾“å…¥ï¼‰ã€‚\n",
    "*   **åŠŸèƒ½**ï¼šå½“æ‚¨è°ƒç”¨é“¾ï¼ˆChainï¼‰æ—¶ï¼ŒLangchain ä¼šä½¿ç”¨è¿™ä¸ªæ¨¡æ¿ï¼Œå¹¶å°†æ‚¨æä¾›çš„å…·ä½“ `history` å’Œ `input` å€¼å¡«å……åˆ°å ä½ç¬¦ä¸­ï¼Œç”Ÿæˆæœ€ç»ˆå‘é€ç»™æ¨¡å‹çš„å®Œæ•´æç¤ºã€‚\n",
    "\n",
    "### 3. `LLMChain`\n",
    "\n",
    "é“¾ï¼ˆChainï¼‰æ˜¯ Langchain ä¸­çš„æ ¸å¿ƒæ¦‚å¿µï¼Œå®ƒå°†ä¸åŒçš„ç»„ä»¶ï¼ˆå¦‚æ¨¡å‹ã€æç¤ºæ¨¡æ¿ã€è¾“å‡ºè§£æå™¨ç­‰ï¼‰ä¸²è”èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„å¤„ç†æµç¨‹ã€‚\n",
    "\n",
    "åœ¨æ‚¨çš„ä»£ç ä¸­ï¼š\n",
    "\n",
    "```python\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "```\n",
    "\n",
    "*   **ä½œç”¨**ï¼š`LLMChain` æ˜¯æœ€åŸºç¡€çš„é“¾ç±»å‹ä¹‹ä¸€ã€‚å®ƒå°†ä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹ï¼ˆ`llm`ï¼Œå³æ‚¨åˆ›å»ºçš„ `ChatOpenAI` å®ä¾‹ï¼‰å’Œä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼ˆ`prompt`ï¼Œå³æ‚¨åˆ›å»ºçš„ `ChatPromptTemplate` å®ä¾‹ï¼‰ç»„åˆåœ¨ä¸€èµ·ã€‚\n",
    "*   **åŠŸèƒ½**ï¼šå½“æ‚¨ä½¿ç”¨è¿™ä¸ªé“¾æ—¶ï¼Œå®ƒä¼šè‡ªåŠ¨ï¼š\n",
    "    1.  æ¥æ”¶è¾“å…¥ï¼ˆä¾‹å¦‚ï¼Œä¸€ä¸ªåŒ…å« `history` å’Œ `input` çš„å­—å…¸ï¼‰ã€‚\n",
    "    2.  ä½¿ç”¨ `ChatPromptTemplate` æ ¹æ®è¾“å…¥æ ¼å¼åŒ–æç¤ºã€‚\n",
    "    3.  å°†æ ¼å¼åŒ–åçš„æç¤ºå‘é€ç»™ `ChatOpenAI` æ¨¡å‹ã€‚\n",
    "    4.  è¿”å›æ¨¡å‹çš„è¾“å‡ºã€‚\n",
    "\n",
    "### 4. `invoke`\n",
    "\n",
    "`invoke` æ˜¯ Langchain ä¸­æ‰§è¡Œä¸€ä¸ªé“¾ï¼ˆChainï¼‰æˆ–å¯è¿è¡Œå¯¹è±¡ï¼ˆRunnableï¼‰çš„æ ‡å‡†æ–¹æ³•ã€‚\n",
    "\n",
    "åœ¨æ‚¨çš„ä»£ç ä¸­ï¼š\n",
    "\n",
    "```python\n",
    "res = chain.invoke({\"history\": \"\", \"input\": \"Hi!\"})\n",
    "```\n",
    "\n",
    "*   **ä½œç”¨**ï¼šå®ƒè§¦å‘ `LLMChain` çš„æ‰§è¡Œæµç¨‹ã€‚\n",
    "*   **åŠŸèƒ½**ï¼š\n",
    "    *   æ‚¨ä¼ é€’ç»™ `invoke` æ–¹æ³•çš„å­—å…¸ `{\"history\": \"\", \"input\": \"Hi!\"}` æä¾›äº†å¡«å……æç¤ºæ¨¡æ¿ä¸­å ä½ç¬¦æ‰€éœ€çš„å€¼ã€‚\n",
    "    *   `invoke` ä¼šå¯åŠ¨é“¾çš„å¤„ç†ï¼šæ ¼å¼åŒ–æç¤º -> è°ƒç”¨ LLM -> è·å–ç»“æœã€‚\n",
    "    *   æ‰§è¡Œå®Œæˆåï¼Œ`invoke` è¿”å›æ¨¡å‹å¤„ç†åçš„ç»“æœï¼Œè¿™ä¸ªç»“æœé€šå¸¸æ˜¯ä¸€ä¸ªåŒ…å«æ¨¡å‹å›å¤æ–‡æœ¬çš„å­—å…¸ï¼ˆåœ¨æ‚¨çš„æƒ…å†µä¸‹ï¼Œ`res` ä¼šåŒ…å«ç±»ä¼¼ `{'text': 'Hello! How can I help you today?'}` çš„å†…å®¹ï¼Œå…·ä½“å–å†³äºæ¨¡å‹çš„å›ç­”ï¼‰ã€‚\n",
    "\n",
    "æ€»è€Œè¨€ä¹‹ï¼Œè¿™å››ä¸ªç»„ä»¶ååŒå·¥ä½œï¼š\n",
    "\n",
    "*   æ‚¨ä½¿ç”¨ `ChatOpenAI` æ¥è¿æ¥åˆ°ä¸€ä¸ªå…·ä½“çš„è¯­è¨€æ¨¡å‹ã€‚\n",
    "*   æ‚¨ä½¿ç”¨ `ChatPromptTemplate` æ¥å®šä¹‰å¦‚ä½•ä¸è¯¥æ¨¡å‹å¯¹è¯ã€‚\n",
    "*   æ‚¨ä½¿ç”¨ `LLMChain` å°†æ¨¡å‹å’Œæç¤ºæ¨¡æ¿ç»‘å®šåœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªå¯æ‰§è¡Œå•å…ƒã€‚\n",
    "*   æœ€åï¼Œæ‚¨ä½¿ç”¨ `invoke` æ–¹æ³•å¹¶ä¼ å…¥å…·ä½“æ•°æ®æ¥è¿è¡Œè¿™ä¸ªé“¾ï¼Œä»è€Œå¾—åˆ°æ¨¡å‹çš„å“åº”ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': '', 'input': 'Hi!', 'text': 'Hello! ğŸ‘‹ How can I assist you today?'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from typing import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from utils import get_config\n",
    "\n",
    "\n",
    "# å®šä¹‰çŠ¶æ€å’Œé“¾\n",
    "class State(TypedDict):\n",
    "    history: str\n",
    "    response: str\n",
    "\n",
    "\n",
    "api_key, base_url, model = get_config()\n",
    "llm = ChatOpenAI(\n",
    "            openai_api_key=api_key,\n",
    "            openai_api_base=base_url,\n",
    "            model_name=model\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{history}\\nUser: {input}\")\n",
    "])\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "res = chain.invoke({\"history\": \"\", \"input\": \"Hi!\"})\n",
    "print(res)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 教学内容\n",
    "\n",
    "好的，我来为您介绍 Langchain 中这四个核心组件：\n",
    "\n",
    "### 1. `ChatOpenAI`\n",
    "\n",
    "这是 Langchain 中与 OpenAI 聊天模型（如 GPT-3.5, GPT-4）进行交互的接口。在您的代码中：\n",
    "\n",
    "```python\n",
    "llm = ChatOpenAI(\n",
    "            openai_api_key=api_key,\n",
    "            openai_api_base=base_url,\n",
    "            model_name=model\n",
    ")\n",
    "```\n",
    "\n",
    "*   **作用**：它封装了调用 OpenAI API 的所有细节，包括身份验证（`openai_api_key`）、API 端点（`openai_api_base`，如果您使用的是自定义服务或代理）以及指定要使用的模型（`model_name`）。\n",
    "*   **功能**：创建 `ChatOpenAI` 实例后，您就可以用它来发送请求给大语言模型并接收模型的回复。\n",
    "\n",
    "### 2. `ChatPromptTemplate`\n",
    "\n",
    "提示模板（Prompt Template）是用来构建发送给大语言模型的输入（即提示）的。`ChatPromptTemplate` 专门用于构建聊天模型的提示，通常包含一系列消息（系统消息、人类用户消息、AI 助手消息）。\n",
    "\n",
    "在您的代码中：\n",
    "\n",
    "```python\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{history}\\nUser: {input}\")\n",
    "])\n",
    "```\n",
    "\n",
    "*   **作用**：它定义了与模型交互的结构和上下文。\n",
    "    *   `(\"system\", \"You are a helpful assistant.\")`：这是一条系统消息，用于设定 AI 的角色或行为准则。\n",
    "    *   `(\"human\", \"{history}\\nUser: {input}\")`：这是一条人类用户消息的模板。它包含了两个占位符：`{history}`（用于传入之前的对话历史）和 `{input}`（用于传入用户当前输入）。\n",
    "*   **功能**：当您调用链（Chain）时，Langchain 会使用这个模板，并将您提供的具体 `history` 和 `input` 值填充到占位符中，生成最终发送给模型的完整提示。\n",
    "\n",
    "### 3. `LLMChain`\n",
    "\n",
    "链（Chain）是 Langchain 中的核心概念，它将不同的组件（如模型、提示模板、输出解析器等）串联起来，形成一个完整的处理流程。\n",
    "\n",
    "在您的代码中：\n",
    "\n",
    "```python\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "```\n",
    "\n",
    "*   **作用**：`LLMChain` 是最基础的链类型之一。它将一个大语言模型（`llm`，即您创建的 `ChatOpenAI` 实例）和一个提示模板（`prompt`，即您创建的 `ChatPromptTemplate` 实例）组合在一起。\n",
    "*   **功能**：当您使用这个链时，它会自动：\n",
    "    1.  接收输入（例如，一个包含 `history` 和 `input` 的字典）。\n",
    "    2.  使用 `ChatPromptTemplate` 根据输入格式化提示。\n",
    "    3.  将格式化后的提示发送给 `ChatOpenAI` 模型。\n",
    "    4.  返回模型的输出。\n",
    "\n",
    "### 4. `invoke`\n",
    "\n",
    "`invoke` 是 Langchain 中执行一个链（Chain）或可运行对象（Runnable）的标准方法。\n",
    "\n",
    "在您的代码中：\n",
    "\n",
    "```python\n",
    "res = chain.invoke({\"history\": \"\", \"input\": \"Hi!\"})\n",
    "```\n",
    "\n",
    "*   **作用**：它触发 `LLMChain` 的执行流程。\n",
    "*   **功能**：\n",
    "    *   您传递给 `invoke` 方法的字典 `{\"history\": \"\", \"input\": \"Hi!\"}` 提供了填充提示模板中占位符所需的值。\n",
    "    *   `invoke` 会启动链的处理：格式化提示 -> 调用 LLM -> 获取结果。\n",
    "    *   执行完成后，`invoke` 返回模型处理后的结果，这个结果通常是一个包含模型回复文本的字典（在您的情况下，`res` 会包含类似 `{'text': 'Hello! How can I help you today?'}` 的内容，具体取决于模型的回答）。\n",
    "\n",
    "总而言之，这四个组件协同工作：\n",
    "\n",
    "*   您使用 `ChatOpenAI` 来连接到一个具体的语言模型。\n",
    "*   您使用 `ChatPromptTemplate` 来定义如何与该模型对话。\n",
    "*   您使用 `LLMChain` 将模型和提示模板绑定在一起，形成一个可执行单元。\n",
    "*   最后，您使用 `invoke` 方法并传入具体数据来运行这个链，从而得到模型的响应。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': '', 'input': 'Hi!', 'text': 'Hello! 👋 How can I assist you today?'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from typing import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from utils import get_config\n",
    "\n",
    "\n",
    "# 定义状态和链\n",
    "class State(TypedDict):\n",
    "    history: str\n",
    "    response: str\n",
    "\n",
    "\n",
    "api_key, base_url, model = get_config()\n",
    "llm = ChatOpenAI(\n",
    "            openai_api_key=api_key,\n",
    "            openai_api_base=base_url,\n",
    "            model_name=model\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{history}\\nUser: {input}\")\n",
    "])\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "res = chain.invoke({\"history\": \"\", \"input\": \"Hi!\"})\n",
    "print(res)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
